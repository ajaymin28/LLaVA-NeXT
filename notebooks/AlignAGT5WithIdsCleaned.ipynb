{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from utils.utilities import remove_ids, eval_tagging_scores, calculate_accuracy_varying_lengths\n",
    "import os\n",
    "import copy\n",
    "import os\n",
    "from json import encoder\n",
    "encoder.FLOAT_REPR = lambda o: format(o, '.2f')\n",
    "from utils.SemanticMatch import T5ForSoftMatching, BertForSoftMatching, T5V1_1ForSoftMatching\n",
    "from utils.misc import remove_entity_index,check_alignment,cal_triplet_acc_score_vrdFormer\n",
    "from utils.eval_func import eval_pred_data\n",
    "import os\n",
    "class NumpyFloatValuesEncoder(json.JSONDecoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.float32):\n",
    "            return float(obj)\n",
    "        return json.JSONDecoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utilities import get_AG_annotations_framewise, AG_Objects,AG_relationsCombined\n",
    "\n",
    "dataset_name = \"ActionGnome\"\n",
    "\n",
    "splits = [\"test\"]\n",
    "# VIDEO_ROOT_PATH = \"/groups/sernam/datasets/ActionGenome/Charades_v1_480\"\n",
    "# OUTPUT_JSON_DIR = \"/home/jbhol/dso/gits/ActionGenome/inference/AG_llava_annotations_v5_3\"\n",
    "AG_ANNOTATIONS_DIR = \"D:\\\\Datasets\\\\ActionGenome\\\\data\"\n",
    "AG_ANNOTATIONS_VID_DIR = \"D:\\\\Datasets\\\\ActionGenome\\\\Charades_v1_480\"\n",
    "CHUNK_N = 1000 # Q&A will be chunked into CHUNK_N parts\n",
    "AG_Annotations,dataset_meta,video_frame_data = get_AG_annotations_framewise(AG_ANNOTATIONS_DIR=AG_ANNOTATIONS_DIR, \n",
    "                                                                            subset=splits[0])\n",
    "\n",
    "DATASET_DATA = {\n",
    "    \"dataset_subjects\": AG_Objects,\n",
    "    \"dataset_objects\": AG_Objects,\n",
    "    \"dataset_predicates\": AG_relationsCombined\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\".\\\\inference_outputs_onevision\\\\vidvrd_v13_indexedlist3\\\\vidvrd_inference_val_vidvrd_v13_indexedlist3.json\") as f:\n",
    "#     pred_data = eval(json.loads(f.read()))\n",
    "# PredJsons = [\n",
    "#     \"inference_outputs_onevision\\\\ConsolidatedResults\\\\llava_ov\\\\AG\\\\[test][onevision]_AG_annotations_v5_3_p00_e01_all_mm_tune\\\\ActionGnome_inference_val.json\"\n",
    "# ]\n",
    "# with open(PredJsons[0]) as f:\n",
    "#     pred_data = json.loads(f.read())\n",
    "# cleaned_outputs = {}\n",
    "# for video_id, video_data in pred_data.items():\n",
    "#     if video_id not in cleaned_outputs.keys():\n",
    "#         cleaned_outputs[video_id] = {}\n",
    "\n",
    "#     for block_id,block_data in video_data.items():\n",
    "#         if block_id not in cleaned_outputs[video_id]:\n",
    "#             cleaned_outputs[video_id][block_id] = {}\n",
    "\n",
    "#         cleaned_outputs[video_id][block_id] = {\n",
    "#             \"frames\": block_data[\"frames\"],\n",
    "#             \"GT_triplets\": block_data[\"GT_triplets\"],\n",
    "#             \"triplets\": block_data[\"triplets\"],\n",
    "#             # \"triplets_bb\": block_data[\"triplets_bb\"],\n",
    "#             # \"GT_triplets_BB\": block_data[\"GT_triplets_BB\"]\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidate_results(jsons_list):\n",
    "    cleaned_outputs = {}\n",
    "    for rawData in jsons_list:\n",
    "        triplet_key = \"cleaned_output\"\n",
    "        print(rawData)\n",
    "        with open(rawData) as f:\n",
    "            raw_data = json.loads(f.read())\n",
    "            for raw_data_item in [raw_data]:\n",
    "                for video_id, video_data in raw_data_item.items():\n",
    "                    if video_id not in cleaned_outputs.keys():\n",
    "                        cleaned_outputs[video_id] = {}\n",
    "                    for block_id,block_data in video_data.items():\n",
    "                        \n",
    "                        if \"cleaned_output\" not in block_data.keys() and \"triplets\" not in block_data.keys():\n",
    "                            continue\n",
    "\n",
    "                        if \"cleaned_output\" not in block_data.keys():\n",
    "                            triplet_key = \"triplets\"\n",
    "                        else:\n",
    "                            block_data[\"triplets\"] = copy.deepcopy(block_data[\"cleaned_output\"])\n",
    "                            del block_data[\"cleaned_output\"]\n",
    "                            \n",
    "                        # if \"triplets\" not in block_data.keys():\n",
    "                        #     triplet_key = \"cleaned_output\"\n",
    "\n",
    "                        if \"triplets\" in block_data.keys():\n",
    "                            if block_id not in cleaned_outputs[video_id]:\n",
    "                                cleaned_outputs[video_id][block_id] = {}\n",
    "\n",
    "                            cleaned_outputs[video_id][block_id] = {\n",
    "                                \"frames\": block_data[\"frames\"],\n",
    "                                \"GT_triplets\": block_data[\"GT_triplets\"],\n",
    "                                \"triplets\": block_data[\"triplets\"],\n",
    "                                # \"triplets\": block_data[\"cleaned_output\"],\n",
    "                            }\n",
    "    return cleaned_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jsons_ToCombine = [\n",
    "    # # p00\n",
    "    # \"inference_outputs_onevision\\\\ConsolidatedResults\\\\llava_ov\\\\AG\\\\FFT\\\\[test][onevision]_AG_annotations_v5_3_p0_e01\\\\results_raw_response.json\",\n",
    "    # \"inference_outputs_onevision\\\\ConsolidatedResults\\\\llava_ov\\\\AG\\\\FFT\\\\[test][onevision]_AG_annotations_v5_3_p0_e01_rem\\\\ActionGnomestart_idx_1399_inference_val_raw_response.json\"\n",
    "\n",
    "    # #p01\n",
    "    # \"inference_outputs_onevision\\\\ConsolidatedResults\\\\llava_ov\\\\AG\\\\FFT\\\\[test][onevision]_AG_annotations_v5_3_p01_e01_fulltune\\\\ActionGnome_inference_val_raw_response.json\",\n",
    "    # \"inference_outputs_onevision\\\\ConsolidatedResults\\\\llava_ov\\\\AG\\FFT\\\\[test][onevision]_AG_annotations_v5_3_p01_e01_fulltune\\\\ActionGnomestart_idx_955_inference_val_raw_response.json\"\n",
    "    \n",
    "    # ## p02\n",
    "    # \"inference_outputs_onevision\\\\ConsolidatedResults\\\\llava_ov\\\\AG\\FFT\\\\[test][onevision]FFT_AG_annotations_v5_3_p02_e01\\ActionGnome_inference_val_raw_response.json\"\n",
    "\n",
    "    # ## P06\n",
    "    # \"inference_outputs_onevision\\\\ConsolidatedResults\\\\llava_ov\\\\AG\\\\FFT\\\\[test][onevision]_AG_annotations_v5_3_p06_e01_fulltune\\\\ActionGnome_inference_val_raw_response.json\",\n",
    "    # \"inference_outputs_onevision\\\\ConsolidatedResults\\\\llava_ov\\\\AG\\\\FFT\\\\[test][onevision]_AG_annotations_v5_3_p06_e01_fulltune\\\\ActionGnomestart_idx_760_inference_val_raw_response.json\"\n",
    "\n",
    "    # ## p023\n",
    "    # \"inference_outputs_onevision\\ConsolidatedResults\\llava_ov\\AG\\FFT\\[test][onevision]_AG_annotations_v5_3_p023_e01_fulltune\\ActionGnome_inference_val_raw_response.json\",\n",
    "    # \"inference_outputs_onevision\\ConsolidatedResults\\llava_ov\\AG\\FFT\\[test][onevision]_AG_annotations_v5_3_p023_e01_1111_fulltune\\ActionGnomestart_idx_1111_inference_val_raw_response.json\",\n",
    "    # \"inference_outputs_onevision\\ConsolidatedResults\\llava_ov\\AG\\FFT\\[test][onevision]_AG_annotations_v5_3_p023_e01_1673_fulltune\\ActionGnomestart_idx_1673_inference_val_raw_response.json\",\n",
    "    # \"inference_outputs_onevision\\ConsolidatedResults\\llava_ov\\AG\\FFT\\[test][onevision]_AG_annotations_v5_3_p023_e01_1673_fulltune_run2\\ActionGnome_inference_val_raw_response.json\"\n",
    "\n",
    "    # ## LLAVA Qwen2\n",
    "    # \"inference_outputs_onevision\\\\ConsolidatedResults\\\\llava_vid_qwen2\\\\[test][llavavid_qwen2]_AG_annotations_v5_3_p06_e01_lora\\\\ActionGnome_inference_val_raw_response_json-fixer.json\",\n",
    "    # \"inference_outputs_onevision\\\\ConsolidatedResults\\\\llava_vid_qwen2\\\\[test][llavavid_qwen2]_AG_annotations_v5_3_p06_e01_lora_1426\\\\ActionGnomestart_idx_1426_inference_val_raw_response_json-fixer.json\"\n",
    "\n",
    "    # # P23\n",
    "    # \"inference_outputs_onevision\\ConsolidatedResults\\llava_vid_qwen2\\[test][llavavid_qwen2]_AG_annotations_v5_3_p023_e01_lora\\ActionGnome_inference_val_raw_response.json\",\n",
    "    # \"inference_outputs_onevision\\ConsolidatedResults\\llava_vid_qwen2\\[test][llavavid_qwen2]_AG_annotations_v5_3_p023_e01_lora_704\\ActionGnomestart_idx_704_inference_val_raw_response.json\",\n",
    "\n",
    "\n",
    "\n",
    "]\n",
    "cleaned_outputs = consolidate_results(Jsons_ToCombine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cleaned_outputs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LORA_AG_RawDataToClean = [\n",
    "    \"inference_outputs_onevision\\\\ConsolidatedResults\\\\llava_ov\\\\AG\\\\[test][onevision]_AG_annotations_v5_3_p02_e01_all_mm_tune\\\\ActionGnome_inference_val_raw_response.json\",\n",
    "    \"inference_outputs_onevision\\\\ConsolidatedResults\\\\llava_ov\\\\AG\\\\[test][onevision]_AG_annotations_v5_3_p06_e01\\\\ActionGnome_inference_val_raw_response.json\",\n",
    "    \"inference_outputs_onevision\\\\ConsolidatedResults\\\\llava_ov\\\\AG\\\\[test][onevision]_AG_annotations_v5_3_p023_e01_all_mm_tune\\\\ActionGnome_inference_val_raw_response.json\",\n",
    "    \"inference_outputs_onevision\\\\ConsolidatedResults\\\\llava_ov\\AG\\\\[test][onevision]_AG_annotations_v5_3_p01_e01\\\\results_raw_response.json\",\n",
    "    \"inference_outputs_onevision\\\\AG\\\\[test][onevision]_AG_annotations_v5_3_p00_e01_all_mm_tune\\\\ActionGnome_inference_val_json-fixer.json\"\n",
    "]\n",
    "\n",
    "cleaned_outputs = {}\n",
    "for rawData in [LORA_AG_RawDataToClean[4]]:\n",
    "    print(rawData)\n",
    "    with open(rawData) as f:\n",
    "        raw_data = json.loads(f.read())\n",
    "        for raw_data_item in [raw_data]:\n",
    "            for video_id, video_data in raw_data_item.items():\n",
    "                if video_id not in cleaned_outputs.keys():\n",
    "                    cleaned_outputs[video_id] = {}\n",
    "                for block_id,block_data in video_data.items():\n",
    "                    if block_id not in cleaned_outputs[video_id]:\n",
    "                        cleaned_outputs[video_id][block_id] = {}\n",
    "                    cleaned_outputs[video_id][block_id] = {\n",
    "                        \"frames\": block_data[\"frames\"],\n",
    "                        \"GT_triplets\": block_data[\"GT_triplets\"],\n",
    "                        \"triplets\": block_data[\"triplets\"],\n",
    "                        # \"triplets\": block_data[\"cleaned_output\"],\n",
    "                    }\n",
    "# total_keys = 0\n",
    "# for raw_data_item in [raw_data,raw_data2]:\n",
    "#     print(len(raw_data_item.keys()))\n",
    "#     total_keys +=len(raw_data_item.keys())\n",
    "# print(\"total\", total_keys)\n",
    "# len(raw_data.keys()), len(raw_data2.keys()), len(raw_data.keys())+len(raw_data2.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.utilities import pre_clean_prediction_data_v18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredConfig:\n",
    "    topk = 1\n",
    "pred_config = PredConfig()\n",
    "# before_alignment, all_triplets_pairs, [new_subjects,new_predicates,new_objects] = eval_pred_data(data=cleaned_outputs,**DATASET_DATA, PredConfig=pred_config)\n",
    "\n",
    "for R in [1,10,20,50,100]:\n",
    "    pred_config.topk = R\n",
    "    before_alignment, all_triplets_pairs, [new_subjects,new_predicates,new_objects] = eval_pred_data(data=cleaned_outputs,**DATASET_DATA, PredConfig=pred_config)\n",
    "\n",
    "    print(f\"TOP-{R}\",before_alignment[\"VRDFormer_Logic\"][\"triplet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference_output_dir = \"AG_llava_annotations/inference_output/[test][onevision]_AG_annotations_v5_3_p0_e01_combined\"\n",
    "# dataset_name = \"ActionGnome\"\n",
    "# os.makedirs(inference_output_dir,exist_ok=True)\n",
    "# try:\n",
    "#     before_alignment[\"dataset_meta\"] ={\n",
    "#         \"dataset_triplets_existing\": DATASET_DATA,\n",
    "#         \"dataset_triplets_new\": {\n",
    "#             \"dataset_subjects\": new_subjects,\n",
    "#             \"dataset_objects\": new_objects,\n",
    "#             \"dataset_predicates\": new_predicates\n",
    "#         }\n",
    "#     }\n",
    "# except Exception as e:\n",
    "#     pass\n",
    "\n",
    "# try:\n",
    "#     outputfile = f\"{inference_output_dir}/{dataset_name}_inference_val.json\"\n",
    "#     # outputfile = f\"{inference_output_dir}/results.json\"\n",
    "#     with open(outputfile, \"w\") as f:\n",
    "#         json.dump(cleaned_outputs,f, indent=4)\n",
    "# except Exception as e:\n",
    "#     print(f\"error saving file: {e}\")\n",
    "\n",
    "# try:\n",
    "#     outputfile = f\"{inference_output_dir}/results_eval_data.json\"\n",
    "#     with open(outputfile, \"w\") as f:\n",
    "#         json.dump(before_alignment,f, indent=4)\n",
    "# except Exception as e:\n",
    "#     print(f\"error saving file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(all_triplets_pairs.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_triplets_pairs[\"00607.mp4\"][\"Block0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cleaned_outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VideoId = list(cleaned_outputs.keys())[0]\n",
    "print(VideoId)\n",
    "Blockid = list(cleaned_outputs[VideoId].keys())[0]\n",
    "print(Blockid)\n",
    "\n",
    "\n",
    "frames = copy.deepcopy(cleaned_outputs[VideoId][Blockid][\"frames\"])\n",
    "GT_triplets = copy.deepcopy(cleaned_outputs[VideoId][Blockid][\"GT_triplets\"])\n",
    "triplets = copy.deepcopy(cleaned_outputs[VideoId][Blockid][\"triplets\"])\n",
    "triplets_bb = copy.deepcopy(cleaned_outputs[VideoId][Blockid][\"triplets_bb\"])\n",
    "GT_triplets_BB = copy.deepcopy(cleaned_outputs[VideoId][Blockid][\"GT_triplets_BB\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets_bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_zero_idx = 3\n",
    "current_frame_indexes = frames[frame_zero_idx]\n",
    "\n",
    "current_GT_triplets = GT_triplets[frame_zero_idx]\n",
    "print(current_GT_triplets)\n",
    "current_GT_triplets_bb = GT_triplets_BB[frame_zero_idx]\n",
    "print(current_GT_triplets_bb)\n",
    "\n",
    "# current_pred_triplets = triplets[frame_zero_idx]\n",
    "# print(current_pred_triplets)\n",
    "\n",
    "# current_pred_triplets_bb = triplets_bb[frame_zero_idx]\n",
    "# print(current_pred_triplets_bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_frame_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "font                   = cv2.FONT_HERSHEY_PLAIN\n",
    "bottomLeftCornerOfText = (10,500)\n",
    "fontScale              = 1.0\n",
    "fontColor_GT           = (0,150,255)\n",
    "fontColor_PRED         = (0,255,0)\n",
    "thickness              = 1\n",
    "lineType               = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_id = VideoId\n",
    "capture = cv2.VideoCapture(os.path.join(AG_ANNOTATIONS_VID_DIR,f\"{VideoId}\"))\n",
    "\n",
    "# k=capture.isOpened()\n",
    "# if k==False:\n",
    "#    capture.open(os.path.exists(os.path.join(imagenet_vidvrd_video_path,f\"{video_id}.mp4\")))\n",
    "\n",
    "capture.set(cv2.CAP_PROP_POS_FRAMES,frames[frame_zero_idx])\n",
    "ret, frame = capture.read()\n",
    "print(ret)\n",
    "if ret:\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,w,c = frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utilities import unnormbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets_bb[\"frame-3\"][0][\"dish\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_box = unnormbb(pred_box=copy.deepcopy(triplets_bb[\"frame-3\"][0][\"dish\"]),mask=frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([240,360]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GTboxes = cv2.rectangle(frame, (GT_box[0], GT_box[1]), (GT_box[2], GT_box[3]), (0,0,255), 2)\n",
    "PredBoxes_img = cv2.rectangle(frame, (pred_box[0], pred_box[1]), (pred_box[2], pred_box[3]), (255,0,0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.makedirs(\"AG_llava_annotations\\\\inference_output\\\\Qualitative\\\\lang_adapter\",exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_triplets_pairs[\"00607.mp4\"][\"Block0\"]\n",
    "for video_id, video_data in all_triplets_pairs.items():\n",
    "\n",
    "\n",
    "    capture = cv2.VideoCapture(os.path.join(AG_ANNOTATIONS_VID_DIR,f\"{video_id}\"))\n",
    "\n",
    "    video_save_root = f\"AG_llava_annotations\\\\inference_output\\\\Qualitative\\\\lang_adapter\\\\{video_id}\"\n",
    "    os.makedirs(video_save_root,exist_ok=True)\n",
    "\n",
    "    for block_id, block_data in video_data.items():\n",
    "\n",
    "        video_frame_ids = eval(block_data[\"frames\"])\n",
    "\n",
    "        for frame_zero_idx, frame_data in block_data.items():\n",
    "            if frame_zero_idx==\"frames\":\n",
    "                continue\n",
    "\n",
    "                \n",
    "            actual_frame_idx = video_frame_ids[frame_zero_idx]\n",
    "\n",
    "            GT_triplets = frame_data[\"gt_triplets\"]\n",
    "            pred_triplets = frame_data[\"pred_triplets\"]\n",
    "            \n",
    "            capture.set(cv2.CAP_PROP_POS_FRAMES,int(actual_frame_idx))\n",
    "            ret, frame = capture.read()\n",
    "\n",
    "            sg_mask = np.zeros_like(frame)\n",
    "            text_loc = [10,50]\n",
    "            for f_sg in GT_triplets:\n",
    "                sub,pred,obj = f_sg\n",
    "                cv2.putText(sg_mask, f\"{sub}:{pred}:{obj}\", (text_loc[0], text_loc[1]), font, fontScale,fontColor_GT,thickness,lineType)\n",
    "                text_loc[1] +=30\n",
    "\n",
    "            sg_mask_pred = np.zeros_like(frame)\n",
    "            text_loc = [10,50]\n",
    "            for f_sg in pred_triplets:\n",
    "                sub,pred,obj = f_sg\n",
    "                cv2.putText(sg_mask_pred, f\"{sub}:{pred}:{obj}\", (text_loc[0], text_loc[1]), font, fontScale,fontColor_PRED,thickness,lineType)\n",
    "                text_loc[1] +=30\n",
    "\n",
    "            stacked_image = np.hstack([frame,sg_mask,sg_mask_pred])\n",
    "            cv2.imwrite(f\"{video_save_root}\\\\{actual_frame_idx}.jpg\", stacked_image)\n",
    "    capture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printScore(data):\n",
    "    score_str = \"\"\n",
    "    for key in [\"triplet\", \"subject\", \"predicate\", \"object\"]:\n",
    "        precision_before = data[\"VRDFormer_Logic\"][key][\"Precision@1\"]\n",
    "        recall_before = data[\"VRDFormer_Logic\"][key][\"Recall@1\"]\n",
    "        score_str += f\"[{key}: {precision_before:.3f} {recall_before:.3f}]\"\n",
    "    print(score_str)\n",
    "\n",
    "for model_cls in [T5ForSoftMatching]:\n",
    "    model = model_cls()\n",
    "    print(\"using \",model.__class__)\n",
    "    model.register_new_gallery(gallery_name=\"predicates\",gallery_data=AG_relationsCombined)\n",
    "    model.register_new_gallery(gallery_name=\"objects\",gallery_data=AG_Objects)\n",
    "\n",
    "    ALIGNMENT_CONFIDENCE_THR = 0.80 # if less dont replace the entity\n",
    "    ALIGNMENT_MODEL = model\n",
    "\n",
    "    new_predicates_aligned = ALIGNMENT_MODEL.align_entities(data_to_align=new_predicates,gallery_name=\"predicates\",confidence_thr=ALIGNMENT_CONFIDENCE_THR)\n",
    "    new_objects_aligned = ALIGNMENT_MODEL.align_entities(data_to_align=new_objects,gallery_name=\"objects\",confidence_thr=ALIGNMENT_CONFIDENCE_THR)\n",
    "    new_subjects_aligned = ALIGNMENT_MODEL.align_entities(data_to_align=new_subjects,gallery_name=\"objects\",confidence_thr=ALIGNMENT_CONFIDENCE_THR)\n",
    "\n",
    "    ALIGNMENT_DATA = {\n",
    "        'check_alinged': True,\n",
    "        'alinged_subjects': new_subjects_aligned,\n",
    "        'alinged_objects': new_objects_aligned,\n",
    "        'alinged_predicates': new_predicates_aligned\n",
    "    }\n",
    "\n",
    "    after_alignment, all_triplets_pairs_after_alignment, [new_subjects_,new_predicates_,new_objects_] = eval_pred_data(\n",
    "        pred_data,\n",
    "        **DATASET_DATA,\n",
    "        **ALIGNMENT_DATA)\n",
    "\n",
    "    print() \n",
    "    printScore(before_alignment)\n",
    "    print(f\"### after alignment with {model.__class__}\")\n",
    "    printScore(after_alignment)\n",
    "    print(cal_triplet_acc_score_vrdFormer(before_alignment), cal_triplet_acc_score_vrdFormer(after_alignment))\n",
    "    print()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_alignment,after_alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_subj_str = \"\"\n",
    "for subj in new_subjects:\n",
    "    new_subj_str += f\" '{subj}',\"\n",
    "print(new_subj_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_obj_str = \"\"\n",
    "for obj in new_objects:\n",
    "    new_obj_str += f\" '{obj}',\"\n",
    "print(new_obj_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_predicates_str = \"\"\n",
    "for pred in new_predicates:\n",
    "    new_predicates_str += f\" '{pred}',\"\n",
    "print(new_predicates_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
