{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from utils.utilities import remove_ids, eval_tagging_scores, calculate_accuracy_varying_lengths\n",
    "import os\n",
    "import copy\n",
    "\n",
    "from utils.SemanticMatch import T5ForSoftMatching, BertForSoftMatching, T5V1_1ForSoftMatching\n",
    "from utils.misc import remove_entity_index,check_alignment,cal_triplet_acc_score_vrdFormer\n",
    "from utils.eval_func import eval_pred_data\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_prep.vidvrd2dataset import VidOR,VidVRD\n",
    "import os\n",
    "\n",
    "splits = [\"train\",\"test\"]\n",
    "imagenet_vidvrd_root = \"D:/Datasets/VidVRD/VidVRD-II/data\"\n",
    "imagenet_vidvrd_video_path = os.path.join(imagenet_vidvrd_root, \"videos\")\n",
    "\n",
    "dataset = VidVRD(imagenet_vidvrd_root, imagenet_vidvrd_video_path, splits)\n",
    "vidvrd_predicates = list(dataset.pred2pid.keys())\n",
    "vidvrd_objects = list(dataset.so2soid.keys())\n",
    "\n",
    "vidvrd_predicates = [element.replace(\"_\", \" \") for element in vidvrd_predicates]\n",
    "\n",
    "DATASET_DATA = {\n",
    "    \"dataset_subjects\": vidvrd_objects,\n",
    "    \"dataset_objects\": vidvrd_objects,\n",
    "    \"dataset_predicates\": vidvrd_predicates\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"inference_outputs_onevision_old\\\\vidvrd_v14_withid_quad_customprompt\\\\vidvrd_inference_val_vidvrd_v14_withid_quad_customprompt.json\") as f:\n",
    "    pred_data = eval(json.loads(f.read()))\n",
    "# with open(\"inference_outputs_onevision\\\\[test][onevision]_vidvrd_annotations_v5_3_p01_e01\\\\vidvrd_inference_val_[test][onevision]_vidvrd_annotations_v5_3_p01_e01.json\") as f:\n",
    "#     pred_data = eval(json.loads(f.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"inference_outputs_onevision\\\\vidvrd_v13_indexedlist3\\\\vidvrd_inference_val_raw_response_vidvrd_v13_indexedlist3.json\") as f:\n",
    "#     raw_data = eval(json.loads(f.read()))\n",
    "# with open(\".\\\\inference_outputs_onevision\\\\vidvrd_v14_withid_quad_customprompt\\\\vidvrd_inference_val_raw_response_vidvrd_v14_withid_quad_customprompt.json\") as f:\n",
    "#     raw_data = eval(json.loads(f.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:13<00:00, 14.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP-1 {'Precision@1': 0.1129, 'Recall@1': 0.0414}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:13<00:00, 15.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP-10 {'Precision@1': 0.0893, 'Recall@1': 0.0963}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:14<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP-20 {'Precision@1': 0.0888, 'Recall@1': 0.0966}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:15<00:00, 13.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP-50 {'Precision@1': 0.0889, 'Recall@1': 0.0968}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:14<00:00, 13.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP-100 {'Precision@1': 0.0889, 'Recall@1': 0.0968}\n"
     ]
    }
   ],
   "source": [
    "class PredConfig:\n",
    "    topk = 1\n",
    "pred_config = PredConfig()\n",
    "\n",
    "for R in [1,10,20,50,100]:\n",
    "    pred_config.topk = R\n",
    "    before_alignment, all_triplets_pairs, [new_subjects,new_predicates,new_objects] = eval_pred_data(data=pred_data,**DATASET_DATA, PredConfig=pred_config)\n",
    "\n",
    "    print(f\"TOP-{R}\",before_alignment[\"VRDFormer_Logic\"][\"triplet\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using  <class 'utils.SemanticMatch.T5ForSoftMatching'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [00:06<00:00, 20.97it/s]\n",
      "100%|██████████| 35/35 [00:00<00:00, 46.27it/s]\n",
      " 27%|██▋       | 89/335 [00:01<00:05, 48.86it/s]"
     ]
    }
   ],
   "source": [
    "def printScore(data):\n",
    "    score_str = \"\"\n",
    "    for key in [\"triplet\", \"subject\", \"predicate\", \"object\"]:\n",
    "        precision_before = data[\"VRDFormer_Logic\"][key][\"Precision@1\"]\n",
    "        recall_before = data[\"VRDFormer_Logic\"][key][\"Recall@1\"]\n",
    "        score_str += f\"[{key}: {precision_before:.3f} {recall_before:.3f}]\"\n",
    "    print(score_str)\n",
    "\n",
    "for model_cls in [T5ForSoftMatching]:\n",
    "    model = model_cls()\n",
    "    print(\"using \",model.__class__)\n",
    "    model.register_new_gallery(gallery_name=\"predicates\",gallery_data=vidvrd_predicates)\n",
    "    model.register_new_gallery(gallery_name=\"objects\",gallery_data=vidvrd_objects)\n",
    "\n",
    "    ALIGNMENT_CONFIDENCE_THR = 0.01 # if less dont replace the entity\n",
    "    ALIGNMENT_MODEL = model\n",
    "\n",
    "    new_predicates_aligned = ALIGNMENT_MODEL.align_entities(data_to_align=new_predicates,gallery_name=\"predicates\",confidence_thr=ALIGNMENT_CONFIDENCE_THR)\n",
    "    new_objects_aligned = ALIGNMENT_MODEL.align_entities(data_to_align=new_objects,gallery_name=\"objects\",confidence_thr=ALIGNMENT_CONFIDENCE_THR)\n",
    "    new_subjects_aligned = ALIGNMENT_MODEL.align_entities(data_to_align=new_subjects,gallery_name=\"objects\",confidence_thr=ALIGNMENT_CONFIDENCE_THR)\n",
    "\n",
    "    ALIGNMENT_DATA = {\n",
    "        'check_alinged': True,\n",
    "        'alinged_subjects': new_subjects_aligned,\n",
    "        'alinged_objects': new_objects_aligned,\n",
    "        'alinged_predicates': new_predicates_aligned\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    for R in [1,10,20,50,100]:\n",
    "        pred_config.topk = R\n",
    "\n",
    "        after_alignment, all_triplets_pairs_after_alignment, [new_subjects_,new_predicates_,new_objects_] = eval_pred_data(\n",
    "        pred_data,\n",
    "        **DATASET_DATA,\n",
    "        **ALIGNMENT_DATA,PredConfig=pred_config)\n",
    "\n",
    "        # before_alignment, all_triplets_pairs, [new_subjects,new_predicates,new_objects] = eval_pred_data(data=pred_data,**DATASET_DATA, PredConfig=pred_config)\n",
    "\n",
    "        print(f\"TOP-{R}\",after_alignment[\"VRDFormer_Logic\"][\"triplet\"])\n",
    "\n",
    "    \n",
    "\n",
    "    print() \n",
    "    printScore(before_alignment)\n",
    "    print(f\"### after alignment with {model.__class__}\")\n",
    "    printScore(after_alignment)\n",
    "    print(cal_triplet_acc_score_vrdFormer(before_alignment), cal_triplet_acc_score_vrdFormer(after_alignment))\n",
    "    print()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_alignment,after_alignment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
